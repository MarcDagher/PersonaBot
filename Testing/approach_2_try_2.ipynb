{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 2, second try:\n",
    "- Scientist receives conversation. \n",
    "- Goes through the conversational flow.\n",
    "- Queries the graph.\n",
    "- Save query in history of queries. \n",
    "- Save Query results in history of query results. \n",
    "- ToolMessage is not saved in conversation messages.\n",
    "- Have a variable for the extracted occupations or traits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from langchain_core.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# LangGraph\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# LangSmith\n",
    "from langsmith import traceable\n",
    "\n",
    "# General Imports\n",
    "import os\n",
    "import ast\n",
    "import prompts\n",
    "import operator\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated # to construct the agent's state\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Connect to graph\n",
    "dotenv_path = Path('../.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "os.environ[\"NEO4J_URI\"] = os.getenv('NEO4J_URI')\n",
    "os.environ[\"NEO4J_USERNAME\"] = os.getenv('NEO4J_USERNAME')\n",
    "os.environ[\"NEO4J_PASSWORD\"] = os.getenv('NEO4J_PASSWORD')\n",
    "graph = Neo4jGraph()\n",
    "\n",
    "# Create the tool to be used by the Agent\n",
    "@tool\n",
    "def query_graph(query):\n",
    "  \"\"\"Query from Neo4j knowledge graph using Cypher.\"\"\"\n",
    "  return graph.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Agent's State\n",
    "class AgentState(TypedDict):\n",
    "    conversation: Annotated[list[ AnyMessage ], operator.add]\n",
    "    good_cypher_and_outputs: Annotated[dict[ str, str ], operator.or_]\n",
    "    bad_cypher: Annotated[list[ str ], operator.add]\n",
    "    extracted_data: Annotated[list[ str ], operator.add]\n",
    "\n",
    "    # existing_cyphers: list[str]\n",
    "    graph_data_to_be_used: list[str]\n",
    "\n",
    "# Create Agent\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self, model, tools, system: str):\n",
    "\n",
    "        graph = StateGraph(AgentState) # Initialize a stateful graph\n",
    "        memory = MemorySaver()\n",
    "\n",
    "        graph.add_node(\"personality_scientist\", self.call_groq)\n",
    "        graph.add_node(\"validate_cypher_then_query_graph\", self.validate_cypher_then_query_graph) # Checks if query is new\n",
    "        graph.add_node(\"extract_data\", self.extract_data)\n",
    "        graph.add_node(\"recommend_careers\", self.recommend_careers)\n",
    "\n",
    "        graph.add_conditional_edges(\"personality_scientist\", self.validate_tool_call, {True: 'validate_cypher_then_query_graph', False: END})\n",
    "        graph.add_edge(\"validate_cypher_then_query_graph\", \"extract_data\")\n",
    "        graph.add_edge(\"extract_data\", \"recommend_careers\")\n",
    "        graph.add_edge(\"recommend_careers\", END)\n",
    "        graph.set_entry_point(\"personality_scientist\")\n",
    "\n",
    "        self.graph = graph.compile(checkpointer=memory)\n",
    "        self.system = system\n",
    "        self.tools = {t.name: t for t in tools} # Save the tools' names that can be used\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    ## Helper function that returns the cyphers written before. This is used when calling the LLM\n",
    "    def get_previous_cyphers(self, state: AgentState):\n",
    "        cyphers_list = \"\"\n",
    "        \n",
    "        if len(state['bad_cypher']) > 0:\n",
    "            cyphers_list += f\"Here are previously written cypher codes that did not return an output: {str(state['bad_cypher'])}\"\n",
    "\n",
    "        good_cypher = list(state['good_cypher_and_outputs'].keys())\n",
    "        if len(good_cypher) > 0:\n",
    "            cyphers_list += f\"Here are previously written cypher codes that successfully returned an output: {str(good_cypher)}\"\n",
    "        \n",
    "        if cyphers_list != \"\": \n",
    "            output = \"When you are ready to write the cypher code, use these as help:\" + cyphers_list\n",
    "            return output\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    ## Get the LLM's response and update the Agent's State by adding the response to the messages\n",
    "    @traceable\n",
    "    def call_groq(self, state: AgentState):\n",
    "        previous_cyphers = self.get_previous_cyphers(state = state)\n",
    "        if previous_cyphers:\n",
    "            system_message = f\"{self.system}. {previous_cyphers}\"\n",
    "        else:\n",
    "            system_message = self.system\n",
    "\n",
    "        conversation = [SystemMessage(content=system_message)] + state['conversation']\n",
    "        ai_response = self.model.invoke(conversation)\n",
    "        return {'conversation': [ai_response]}\n",
    "    \n",
    "    ## Check if the model called for an action by checking the last message in the conversation\n",
    "    def validate_tool_call(self, state: AgentState):\n",
    "        ai_message = state['conversation'][-1]\n",
    "        return len(ai_message.tool_calls) > 0\n",
    "    \n",
    "    ## Check if the new cypher codes have already been written by the LLM\n",
    "    def validate_cypher_then_query_graph(self, state: AgentState):\n",
    "        print(f\"\\n------- in validate query\")\n",
    "        tool_calls = state['conversation'][-1].tool_calls\n",
    "\n",
    "        good_cypher_and_outputs = {} # stores the cypher queries that returned an output\n",
    "        bad_cypher = [] # stores the cypher queries that did not return an output\n",
    "        graph_data_to_be_used = [] # stores the queries that the model currently wants to use\n",
    "\n",
    "        # Go over the cypher codes given by the LLM\n",
    "        for i in range(len(tool_calls)):\n",
    "            current_tool_call = tool_calls[i]\n",
    "            new_cypher = current_tool_call['args']['query']\n",
    "\n",
    "            status = None\n",
    "\n",
    "            # Check if tool exists\n",
    "            if current_tool_call['name'] in self.tools:\n",
    "                \n",
    "                # LLM checks if the cypher query has already been made + if it returned an output\n",
    "                if status == None:\n",
    "                    print(f\"----- Checker 1\")\n",
    "                    good_cyphers = list(state['good_cypher_and_outputs'].keys())\n",
    "                    for i in range(len( good_cyphers )):\n",
    "                        key = good_cyphers[i]\n",
    "                        comparison = self.model.invoke(\n",
    "                            prompts.cypher_code_analyst_prompt.format(cypher_code_1=new_cypher, cypher_code_2=key, graph_schema=graph.structured_schema)\n",
    "                            )\n",
    "                        print(f\"\\n-------- {comparison.content}\")\n",
    "                        # If Query exists => Save cypher code to later access the output and give it to the model\n",
    "                        if comparison.content.lower() == \"true\":\n",
    "                            print(\"\\n----- Good Cyphers are similar, save the cypher\")\n",
    "                            graph_data_to_be_used.append(key)\n",
    "                            status = \"good_cypher\"\n",
    "                            break\n",
    "                \n",
    "                # LLM checks if the cypher query has already been made + if it didn't return an output\n",
    "                if status == None:\n",
    "                    print(f\"----- Checker 2\")\n",
    "                    for i in range(len(state['bad_cypher'])):\n",
    "                        comparison = self.model.invoke(\n",
    "                            prompts.cypher_code_analyst_prompt.format(\n",
    "                                cypher_code_1=new_cypher, cypher_code_2=state['bad_cypher'][i], graph_schema=graph.structured_schema)\n",
    "                            )\n",
    "                        # Query exists => LLM should fix the query\n",
    "                        if comparison.content.lower() == \"true\":\n",
    "                            print(\"---- Bad Cyphers are similar, have the LLM query again\")\n",
    "                            status = \"bad_cypher\"\n",
    "                            break\n",
    "\n",
    "                # If the cypher code hasn't been used before => query the graph\n",
    "                if status == None:\n",
    "                    print(f\"----- Checker 3\")\n",
    "                    query_output = self.tools[current_tool_call['name']].invoke(new_cypher)\n",
    "                    result = ToolMessage(content=str(query_output), name=current_tool_call['name'], tool_call_id=current_tool_call['id'])\n",
    "                    \n",
    "                    if result.content not in [\"\", None, '[]']:\n",
    "                        good_cypher_and_outputs[new_cypher] = result.content\n",
    "                        graph_data_to_be_used.append(new_cypher)\n",
    "                        print(\"----- Successfully queried graph\")\n",
    "\n",
    "                    else:\n",
    "                        bad_cypher.append(new_cypher)\n",
    "                        print(\"----- Bad query\")\n",
    "            else:\n",
    "                print(\"tool name not found in list of tools\")\n",
    "\n",
    "        # Save the data that we got in the AgentState\n",
    "        return_statement = {}\n",
    "        if len(good_cypher_and_outputs) > 0: return_statement['good_cypher_and_outputs'] = good_cypher_and_outputs\n",
    "        if len(bad_cypher) > 0: return_statement['bad_cypher'] = bad_cypher\n",
    "        if len(graph_data_to_be_used) > 0: return_statement['graph_data_to_be_used'] = graph_data_to_be_used\n",
    "\n",
    "        return return_statement\n",
    "    \n",
    "    ## Invoke tool\n",
    "    def extract_data(self, state: AgentState):\n",
    "        print('\\n-------> In extract data')\n",
    "\n",
    "        if len(state['graph_data_to_be_used']) > 0:\n",
    "            data_to_give_to_the_LLM = [{cypher: state['good_cypher_and_outputs'][cypher]} for cypher in state['graph_data_to_be_used']]\n",
    "            extracted_data = self.model.invoke(prompts.extractor_prompt.format(queried_data = data_to_give_to_the_LLM))\n",
    "            print(\"----- Data has been extracted\")\n",
    "            return {'extracted_data': [extracted_data.content]}\n",
    "\n",
    "        else:\n",
    "            print(\"No queries to be made\")\n",
    "            return\n",
    "\n",
    "    ## Generate final output\n",
    "    def recommend_careers(self, state: AgentState):\n",
    "        previous_cyphers = self.get_previous_cyphers(state = state)\n",
    "        if previous_cyphers:\n",
    "            system_message = f\"{self.system}. {previous_cyphers}\"\n",
    "        else:\n",
    "            system_message = self.system\n",
    "        \n",
    "        conversation = [SystemMessage(content=system_message)] + state['conversation']\n",
    "\n",
    "        if len(state['graph_data_to_be_used']) > 0:\n",
    "            prompt = conversation + [HumanMessage(content= prompts.recommender_prompt_with_data.format(extracted_data=state['extracted_data'][-1]))]\n",
    "            print(\"----- Giving extracted data to the agent\")\n",
    "            \n",
    "            recommended_careers = self.model.invoke(prompt)\n",
    "            print(\"ready for recommendation\")\n",
    "            return {'conversation': [recommended_careers]}\n",
    "        else:\n",
    "            \n",
    "            prompt = conversation + [HumanMessage(content= prompts.recommender_prompt_without_data)]\n",
    "            print(\"----- No data to give to the agent\")\n",
    "            \n",
    "            ai_output = self.model.invoke(prompt)\n",
    "            print(\"ready for recommendation\")\n",
    "            return {'conversation': [ai_output]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(temperature=0.8, groq_api_key=os.environ[\"GROQ_API_KEY\"], model_name=\"llama-3.1-70b-versatile\", max_retries=2)\n",
    "# model = ChatGroq(temperature=0.0, groq_api_key=os.environ[\"GROQ_API_KEY\"], model_name=\"llama3-70b-8192\")\n",
    "\n",
    "agent = Agent(\n",
    "  model=model, \n",
    "  tools=[query_graph], \n",
    "  system=prompts.personality_scientist_prompt.format(schema=graph.structured_schema)\n",
    "  )\n",
    "\n",
    "# graph_png = Image(agent.graph.get_graph().draw_mermaid_png())\n",
    "# display(graph_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Do you know any occupations that suit my character and include Python and Psychology?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  query_graph (call_mw3e)\n",
      " Call ID: call_mw3e\n",
      "  Args:\n",
      "    query: MATCH (n:Occupation)-[]->(m:Personality_Trait) WHERE m.title CONTAINS 'Psychology' OR n.title CONTAINS 'Python' RETURN n,m\n",
      "\n",
      "------- in validate query\n",
      "----- Checker 1\n",
      "\n",
      "-------- False\n",
      "----- Checker 2\n",
      "----- Checker 3\n",
      "----- Bad query\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  query_graph (call_mw3e)\n",
      " Call ID: call_mw3e\n",
      "  Args:\n",
      "    query: MATCH (n:Occupation)-[]->(m:Personality_Trait) WHERE m.title CONTAINS 'Psychology' OR n.title CONTAINS 'Python' RETURN n,m\n",
      "\n",
      "-------> In extract data\n",
      "No queries to be made\n",
      "----- No data to give to the agent\n",
      "ready for recommendation\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on our conversation, I understand that you:\n",
      "\n",
      "* Are detail-oriented and tend to focus on the details to ensure everything is correct\n",
      "* Are more reserved and reflective, enjoying quieter environments\n",
      "* Tend to approach problems in a logical and analytical way, relying on data and facts to find a solution\n",
      "* Are a team player, enjoying collaboration and working with others towards a common goal\n",
      "* Rely on careful analysis and planning when making decisions\n",
      "* Have an interest in Python and Psychology\n",
      "\n",
      "Considering these traits and your interests, I'd like to suggest a few career paths that might align with your goals. Keep in mind that these are just suggestions, and it's essential to research and explore each career path to find the best fit for you.\n",
      "\n",
      "Here are a few career tracks that combine Python and Psychology:\n",
      "\n",
      "* **Data Analyst in Psychology**: In this role, you'll work with researchers and psychologists to analyze data related to human behavior, cognition, and emotions. You'll use Python to clean, process, and visualize data, and your analytical skills will help you identify trends and patterns.\n",
      "* **Research Assistant in Psychology**: As a research assistant, you'll work with researchers to design and implement studies, collect and analyze data, and help with publication preparation. Your knowledge of Python will be useful in data analysis, and your understanding of psychology will help you design studies and interpret results.\n",
      "* **Human-Computer Interaction (HCI) Specialist**: In this role, you'll work with designers, developers, and psychologists to create user-centered interfaces that are intuitive and effective. You'll use Python to analyze user behavior, and your knowledge of psychology will help you design interfaces that meet human needs.\n",
      "* **Neuroscience Researcher**: As a neuroscience researcher, you'll work with neuroscientists to analyze brain data, develop predictive models, and understand the neural basis of human behavior. You'll use Python to analyze data, and your knowledge of psychology will help you interpret results and design studies.\n",
      "\n",
      "These career paths require a combination of technical skills (Python, data analysis) and domain knowledge (psychology). I hope this gives you some ideas to explore further. If you have any questions or would like to discuss these career paths in more detail, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "thread = {'configurable': {'thread_id': \"100\"}}\n",
    "output = agent.graph.stream({\"conversation\": [HumanMessage(content=\"Do you know any occupations that suit my character and include Python and Psychology?\")], 'graph_data_to_be_used': []}, thread, stream_mode='values')\n",
    "\n",
    "for message in output:\n",
    "    message['conversation'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi'),\n",
       " AIMessage(content=\"Hello, I'm excited to help you discover some fantastic career paths that fit your personality. To get started, I have a couple of questions to help me understand you better.\\n\\nHere's my first question:\\n\\n1. When working on a project, what do you usually focus on: the details to ensure everything is correct, or the overall vision to see the big picture?\", response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 690, 'total_tokens': 765, 'completion_time': 0.301961196, 'prompt_time': 0.228078331, 'queue_time': 0.319569941, 'total_time': 0.530039527}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_5c5d1b5cfb', 'finish_reason': 'stop', 'logprobs': None}, id='run-fb4bc51b-6caf-4dca-a61d-3f4790458186-0', usage_metadata={'input_tokens': 690, 'output_tokens': 75, 'total_tokens': 765}),\n",
       " HumanMessage(content='Option 1'),\n",
       " AIMessage(content=\"You're a detail-oriented person who likes to make sure everything is accurate and in place. That's a great trait to have in many careers.\\n\\nHere's my second question:\\n\\n2. When interacting with others, do you tend to be more reserved and reflective, or outgoing and assertive, enjoying the spotlight and being around people?\", response_metadata={'token_usage': {'completion_tokens': 67, 'prompt_tokens': 777, 'total_tokens': 844, 'completion_time': 0.268091097, 'prompt_time': 0.238595565, 'queue_time': 0.006044371999999992, 'total_time': 0.506686662}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-e097e0ea-1b41-433b-a42b-6fbc2e67f4ed-0', usage_metadata={'input_tokens': 777, 'output_tokens': 67, 'total_tokens': 844}),\n",
       " HumanMessage(content='Option 1'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_p70s', 'function': {'arguments': '{\"query\": \"MATCH (n:Occupation)-[]->(m:Personality_Trait) return n,m\"}', 'name': 'query_graph'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 856, 'total_tokens': 968, 'completion_time': 0.449655188, 'prompt_time': 0.285804109, 'queue_time': 0.04928807700000004, 'total_time': 0.735459297}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0d4a9f62-5c54-49d9-acc0-9890f2871aed-0', tool_calls=[{'name': 'query_graph', 'args': {'query': 'MATCH (n:Occupation)-[]->(m:Personality_Trait) return n,m'}, 'id': 'call_p70s', 'type': 'tool_call'}], usage_metadata={'input_tokens': 856, 'output_tokens': 112, 'total_tokens': 968}),\n",
       " AIMessage(content=\"Based on our conversation, I understand that you're a detail-oriented person who tends to be more reserved and reflective. You also seem to be comfortable with routine and structure, which is characteristic of a Conventional personality trait.\\n\\nConsidering these traits and the extracted data from the query, here are six suitable career paths for you:\\n\\n* **Childcare Worker**: This role involves creating a structured and safe environment for children, which aligns with your Conventional trait. Your attention to detail will also help you ensure the children's needs are met.\\n* **Personal Care Aide**: In this role, you'll work with individuals who require assistance with daily tasks. Your reserved nature will help you build trust with your clients, and your attention to detail will ensure their needs are met.\\n* **Dining Room and Cafeteria Attendant**: This role involves maintaining a clean and organized environment, which aligns with your attention to detail. Your Conventional trait will also help you follow established protocols and procedures.\\n* **Barista**: As a barista, you'll work in a structured environment, following established recipes and procedures. Your attention to detail will help you create high-quality beverages, and your reserved nature will help you interact with customers in a professional manner.\\n* **Host/Hostess**: In this role, you'll work in a fast-paced environment, but your attention to detail will help you manage reservations, seating, and customer requests. Your Conventional trait will also help you follow established protocols and procedures.\\n* **Home Health Aide**: This role involves working with individuals who require assistance with daily tasks in their homes. Your attention to detail will help you ensure their needs are met, and your reserved nature will help you build trust with your clients.\\n\\nThese careers align with your personality traits and offer a structured environment where you can excel. Remember, these are just suggestions, and it's essential to research and explore each career path to find the best fit for you.\", response_metadata={'token_usage': {'completion_tokens': 393, 'prompt_tokens': 1493, 'total_tokens': 1886, 'completion_time': 1.617009312, 'prompt_time': 0.436682774, 'queue_time': 0.5845049649999999, 'total_time': 2.053692086}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b3ae7e594e', 'finish_reason': 'stop', 'logprobs': None}, id='run-38c93796-44ec-479e-b921-e5b57535b282-0', usage_metadata={'input_tokens': 1493, 'output_tokens': 393, 'total_tokens': 1886}),\n",
       " HumanMessage(content='continue the test with 3 more questions please, i feel like something is missing'),\n",
       " AIMessage(content=\"I'd be happy to continue the test to gain a deeper understanding of your personality.\\n\\nHere's my next question:\\n\\n3. When solving problems, what approach do you usually take: analyzing logical data and facts to find a solution, or relying on your intuition and creativity to come up with innovative ideas?\", response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 1362, 'total_tokens': 1423, 'completion_time': 0.244679779, 'prompt_time': 0.388175298, 'queue_time': 4.068586133, 'total_time': 0.632855077}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b6828be2c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-51f135b7-0c2a-47fb-9f22-0730f46c3e9f-0', usage_metadata={'input_tokens': 1362, 'output_tokens': 61, 'total_tokens': 1423}),\n",
       " HumanMessage(content='Option 1'),\n",
       " AIMessage(content=\"You tend to approach problems in a logical and analytical way, relying on data and facts to find a solution. This is a great trait to have in many careers, especially those that require attention to detail and critical thinking.\\n\\nHere's my next question:\\n\\n4. When it comes to social interactions, do you tend to be more of a team player, enjoying collaboration and working with others towards a common goal, or do you prefer to work independently, focusing on your own projects and goals?\", response_metadata={'token_usage': {'completion_tokens': 98, 'prompt_tokens': 1435, 'total_tokens': 1533, 'completion_time': 0.394940694, 'prompt_time': 0.496561606, 'queue_time': 0.963693674, 'total_time': 0.8915023}, 'model_name': 'llama-3.1-70b-versatile', 'system_fingerprint': 'fp_b3ae7e594e', 'finish_reason': 'stop', 'logprobs': None}, id='run-3b63fbdc-78c8-408c-ac95-d789e77c4895-0', usage_metadata={'input_tokens': 1435, 'output_tokens': 98, 'total_tokens': 1533}),\n",
       " HumanMessage(content='Option 1')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agent.graph.get_state(thread).values['conversation'][-1].tool_calls[0]['args']['query']\n",
    "# agent.graph.get_state(thread).values['conversation']\n",
    "# agent.graph.get_state(thread).values\n",
    "\n",
    "state = agent.graph.get_state(thread).values\n",
    "state['good_cypher_and_outputs']\n",
    "state['conversation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool_calls = state['conversation'][-2].tool_calls\n",
    "\n",
    "# good_cypher_and_outputs = {} # stores the cypher queries that returned an output\n",
    "# bad_cypher = [] # stores the cypher queries that did not return an output\n",
    "# graph_data_to_be_used = [] # stores the queries that the model currently wants to use\n",
    "\n",
    "# # Go over the cypher codes given by the LLM\n",
    "# for i in range(len(tool_calls)):\n",
    "#     current_tool_call = tool_calls[i]\n",
    "#     new_cypher = current_tool_call['args']['query']\n",
    "\n",
    "#     status = None\n",
    "\n",
    "#     # Check if tool exists\n",
    "#     if current_tool_call['name'] in agent.tools:\n",
    "        \n",
    "#         # LLM checks if the cypher query has already been made + if it returned an output\n",
    "#         if status == None:\n",
    "#             print(f\"----- Checker 1\")\n",
    "#             good_cyphers = list(state['good_cypher_and_outputs'].keys())\n",
    "#             for i in range(len( good_cyphers )):\n",
    "#                 key = good_cyphers[i]\n",
    "#                 comparison = agent.model.invoke(\n",
    "#                     prompts.cypher_code_analyst_prompt.format(cypher_code_1=new_cypher, cypher_code_2=key, graph_schema=graph.structured_schema)\n",
    "#                     )\n",
    "#                 print(f\"\\n-------- {comparison.content}\")\n",
    "#                 # If Query exists => Save cypher code to later access the output and give it to the model\n",
    "#                 if comparison.content.lower() == \"true\":\n",
    "#                     print(\"\\n----- Good Cyphers are similar, save the cypher\")\n",
    "#                     graph_data_to_be_used.append(key)\n",
    "#                     status = \"good_cypher\"\n",
    "#                     break\n",
    "        \n",
    "#         # LLM checks if the cypher query has already been made + if it didn't return an output\n",
    "#         if status == None:\n",
    "#             print(f\"----- Checker 2\")\n",
    "#             for i in range(len(state['bad_cypher'])):\n",
    "#                 comparison = agent.model.invoke(\n",
    "#                     prompts.cypher_code_analyst_prompt.format(\n",
    "#                         cypher_code_1=new_cypher, cypher_code_2=state['bad_cypher'][i], graph_schema=graph.structured_schema)\n",
    "#                     )\n",
    "#                 # Query exists => LLM should fix the query\n",
    "#                 if comparison.content.lower() == \"true\":\n",
    "#                     print(\"---- Bad Cyphers are similar, have the LLM query again\")\n",
    "#                     status = \"bad_cypher\"\n",
    "#                     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comparison' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcomparison\u001b[49m\u001b[38;5;241m.\u001b[39mcontent)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'comparison' is not defined"
     ]
    }
   ],
   "source": [
    "print(comparison.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_knowledge_graph(data):\n",
    "    head = []\n",
    "    tail = []\n",
    "\n",
    "    # Extract head and tail nodes\n",
    "    for i in range(len(data)):\n",
    "        row = data[i]\n",
    "        keys = list(row.keys())\n",
    "        node_1 = row[keys[0]]['title']\n",
    "        node_2 = row[keys[1]]['title']\n",
    "\n",
    "        head.append(node_1)\n",
    "        tail.append(node_2)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({'head': head, 'tail': tail})\n",
    "\n",
    "    # Create the graph\n",
    "    G = nx.Graph()\n",
    "    for _, row in df.iterrows():\n",
    "        G.add_edge(row['head'], row['tail'], label=\"\")\n",
    "\n",
    "    # Get positions for nodes\n",
    "    pos = nx.fruchterman_reingold_layout(G, k=0.7)\n",
    "\n",
    "    # Create edge traces (lines between nodes)\n",
    "    edge_traces = []\n",
    "    for edge in G.edges():\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        edge_trace = go.Scatter(\n",
    "            x=[x0, x1, None],\n",
    "            y=[y0, y1, None],\n",
    "            mode='lines',\n",
    "            line=dict(width=0.3, color='gray'),\n",
    "            hoverinfo='none'\n",
    "        )\n",
    "        edge_traces.append(edge_trace)\n",
    "\n",
    "    # Assign colors based on whether the node is in the head or tail\n",
    "    node_colors = []\n",
    "    for node in G.nodes():\n",
    "        if node in head:\n",
    "            node_colors.append('lightblue')  # Color for head nodes (node_1)\n",
    "        elif node in tail:\n",
    "            node_colors.append('lightcoral')   # Color for tail nodes (node_2)\n",
    "        else:\n",
    "            node_colors.append('gold')  # Default color\n",
    "\n",
    "    # Create node trace (nodes with their respective colors)\n",
    "    node_trace = go.Scatter(\n",
    "        x=[pos[node][0] for node in G.nodes()],\n",
    "        y=[pos[node][1] for node in G.nodes()],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=10, color=node_colors),  # Use node_colors list for colors\n",
    "        text=[node for node in G.nodes()],\n",
    "        textposition='top center',\n",
    "        hoverinfo='text',\n",
    "        textfont=dict(size=7)\n",
    "    )\n",
    "\n",
    "    # Create edge label trace (optional, for labeling edges)\n",
    "    edge_label_trace = go.Scatter(\n",
    "        x=[(pos[edge[0]][0] + pos[edge[1]][0]) / 2 for edge in G.edges()],\n",
    "        y=[(pos[edge[0]][1] + pos[edge[1]][1]) / 2 for edge in G.edges()],\n",
    "        mode='text',\n",
    "        text=[G[edge[0]][edge[1]]['label'] for edge in G.edges()],\n",
    "        textposition='middle center',\n",
    "        hoverinfo='none',\n",
    "        textfont=dict(size=7)\n",
    "    )\n",
    "\n",
    "    # Create layout\n",
    "    layout = go.Layout(\n",
    "        title='',\n",
    "        titlefont_size=16,\n",
    "        title_x=0.5,\n",
    "        showlegend=False,\n",
    "        hovermode='closest',\n",
    "        margin=dict(b=20, l=5, r=5, t=40),\n",
    "        xaxis_visible=False,\n",
    "        yaxis_visible=False\n",
    "    )\n",
    "\n",
    "    # Create Plotly figure\n",
    "    fig = go.Figure(data=edge_traces + [node_trace, edge_label_trace], layout=layout)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# for i in range(len(state['graph_data_to_be_used'])):\n",
    "g = ast.literal_eval(state['good_cypher_and_outputs']['MATCH (n:Occupation)-[]->(m:Personality_Trait) RETURN n, m'])\n",
    "# display_knowledge_graph(g)\n",
    "g "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
