{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 2:\n",
    "- Scientist receives conversation. \n",
    "- Goes through the conversational flow.\n",
    "- Queries the graph. \n",
    "- Save query in history of queries. \n",
    "- Save Query results in history of query results. \n",
    "- ToolMessage is not saved in conversation messages.\n",
    "- Have a variable for the extracted occupations or traits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangChain\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from langchain_core.tools import tool\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# LangGraph\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# LangSmith\n",
    "from langsmith import traceable\n",
    "\n",
    "# General Imports\n",
    "import os\n",
    "import ast\n",
    "import prompts \n",
    "import operator\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated # to construct the agent's state\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Connect to graph\n",
    "dotenv_path = Path('../.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "os.environ[\"NEO4J_URI\"] = os.getenv('uri')\n",
    "os.environ[\"NEO4J_USERNAME\"] = os.getenv('user_name')\n",
    "os.environ[\"NEO4J_PASSWORD\"] = os.getenv('password')\n",
    "graph = Neo4jGraph()\n",
    "\n",
    "# Create the tool to be used by the Agent\n",
    "@tool\n",
    "def query_graph(query):\n",
    "  \"\"\"Query from Neo4j knowledge graph using Cypher.\"\"\"\n",
    "  return graph.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Agent's State\n",
    "class AgentState(TypedDict):\n",
    "    conversation: Annotated[list[ AnyMessage ], operator.add]\n",
    "    tool_messages: list[ list[AnyMessage] ]\n",
    "    cypher_code_and_query_outputs: Annotated[list[ dict ], operator.add]\n",
    "    extracted_data: Annotated[list[str], operator.add]\n",
    "    query_is_unique: dict\n",
    "    num_queries_made: int\n",
    "\n",
    "\n",
    "# Create Agent\n",
    "class Agent:\n",
    "\n",
    "    def __init__(self, model, tools, system):\n",
    "        self.system = system\n",
    "        self.tools = {t.name: t for t in tools} # Save the tools' names that can be used\n",
    "        self.model = model.bind_tools(tools) # Provide the name of the tools to the agent\n",
    "\n",
    "        graph = StateGraph(AgentState) # Initialize a stateful graph\n",
    "        memory = MemorySaver()\n",
    "\n",
    "        graph.add_node(\"personality_scientist\", self.call_groq) # LLM node\n",
    "        graph.add_node(\"graph_querying_tool\", self.use_tool) # Use tool(query graph) called by the previous message\n",
    "        graph.add_node(\"structure_queried_data\", self.structure_queried_data)\n",
    "        graph.add_node(\"extract_data\", self.extract_data) # Extract data from last query\n",
    "        graph.add_node(\"recommend_careers\", self.recommend_careers)\n",
    "\n",
    "        ## Create edges\n",
    "        graph.add_conditional_edges(\"personality_scientist\", self.validate_tool_call, {False: END, True: \"graph_querying_tool\"})\n",
    "\n",
    "        graph.add_edge(\"graph_querying_tool\", \"structure_queried_data\")\n",
    "        graph.add_edge(\"structure_queried_data\", \"extract_data\")\n",
    "        graph.add_edge(\"extract_data\", \"recommend_careers\")\n",
    "        graph.add_edge(\"recommend_careers\", END)\n",
    "        graph.set_entry_point(\"personality_scientist\")\n",
    "\n",
    "        # Build graph\n",
    "        self.graph = graph.compile(checkpointer=memory)\n",
    "        display(Image(self.graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "    ## Get the LLM's response and update the Agent's State by adding the response to the messages\n",
    "    @traceable\n",
    "    def call_groq(self, state: AgentState):\n",
    "        messages = state['conversation']\n",
    "        \n",
    "        if self.system: \n",
    "            conversation = [SystemMessage(content=self.system)] + messages\n",
    "        \n",
    "        ai_response = self.model.invoke(conversation)\n",
    "\n",
    "        return {'conversation': [ai_response], 'num_queries_made': 0}\n",
    "    \n",
    "    ## Check if the model called for an action by checking the last message in the conversation\n",
    "    def validate_tool_call(self, state: AgentState):\n",
    "        ai_message = state['conversation'][-1]\n",
    "        return len(ai_message.tool_calls) > 0\n",
    "\n",
    "    ## Search for the called tools and invoke them.\n",
    "    ## In our case we have one tool: query_graph, so if the tool was correctly called, validate if the query has already been made\n",
    "    def use_tool(self, state: AgentState):\n",
    "        \n",
    "        tool_calls = state['conversation'][-1].tool_calls\n",
    "        num_queries_made = state['num_queries_made']\n",
    "        query_uniqueness_dict = {'status': True, 'index': None} # Initialize it as true and only change it if query already exists\n",
    "        results = []\n",
    "        \n",
    "        for tool in tool_calls:\n",
    "            print(f\"Calling: {tool['name']}\")\n",
    "\n",
    "            ## Checking if tool not found\n",
    "            if not tool['name'] in self.tools: \n",
    "                print(\"\\n ....tool name not found in list of tools....\")\n",
    "                result = \"tool name was not found in the list of tools, retry\"  # instruct LLM to retry\n",
    "            \n",
    "            ## Checking if the query has already been made before\n",
    "            elif tool['name'] == 'query_graph' and len(state['cypher_code_and_query_outputs']) > 0:\n",
    "                print(\"\\n ---- Tool Use Update ----> checking if query exists\")\n",
    "               \n",
    "                # Get the previously written cypher code\n",
    "                previous_queries = []\n",
    "                for i in range(len(state['cypher_code_and_query_outputs'])):\n",
    "                    cypher = state['cypher_code_and_query_outputs'][i]['cypher_code']\n",
    "                    previous_queries.append((f\"index: {i}\", cypher))\n",
    "                \n",
    "                # Get the current cypher code written by the model\n",
    "                query = tool['args']\n",
    "                print(f\"\\n ---- Tool Use Update ----> previous queries: {previous_queries}, new_query: {query}\")\n",
    "\n",
    "                # Instruct the model to check if query already exists\n",
    "                ai_response = self.model.invoke([\n",
    "                SystemMessage(content=prompts.query_validator_prompt),\n",
    "                HumanMessage(content=f\"new cypher query: {query}. List of queries: {previous_queries}\")\n",
    "                ])\n",
    "                \n",
    "                print(f\"\\n---- Tool Use Update ----> ai_response: {ai_response}\\n\")\n",
    "                \n",
    "                # If query is new, query the graph\n",
    "                if 'none' in ai_response.content.lower():\n",
    "                    print(f\"\\n ---- Tool Use Update ----> new query\")\n",
    "                    try:\n",
    "                        result = self.tools[tool['name']].invoke(tool['args'])\n",
    "                        num_queries_made += 1\n",
    "                    except ValueError as e: # If written cypher code is wrong\n",
    "                        result = f\"ValueError occurred: {str(e)}\"    \n",
    "\n",
    "                # If query already exists, give the model the previous output of this query\n",
    "                else:\n",
    "                    print(f\"\\n ---- Tool Use Update ----> query exists\\n\")\n",
    "                    try:\n",
    "                        index = int(ai_response.content)\n",
    "                        result = state['cypher_code_and_query_outputs'][index]['output']\n",
    "                        query_uniqueness_dict = {'status': False, 'index': index}\n",
    "                    except:\n",
    "                        result = \"Something is wrong. Please make sure to give me the correct index and not an empty string.\\\n",
    "                            example: 0\\\n",
    "                            another example: None\"\n",
    "            \n",
    "            ## If no previous queries have been made, query the graph\n",
    "            else:\n",
    "                print(f\"\\n---- Tool Use Update ----> query is unique\\n\")\n",
    "                try:\n",
    "                    result = self.tools[tool['name']].invoke(tool['args'])\n",
    "                    num_queries_made += 1\n",
    "                except ValueError as e: # If written cypher code is wrong\n",
    "                    result = f\"ValueError occurred: {str(e)}\" \n",
    "\n",
    "            # Save the message returned from the tool\n",
    "            results.append(ToolMessage(tool_call_id=tool['id'], name=tool['name'], content=str(result)))\n",
    "\n",
    "        print(\"Back to the model!\")\n",
    "        return {'tool_messages': [results], 'query_is_unique': query_uniqueness_dict, 'num_queries_made': num_queries_made}\n",
    "    \n",
    "    ## Organize the tool's output as: {'cypher_code': Cypher code, 'output': Query output}\n",
    "    def structure_queried_data(self, state: AgentState):\n",
    "        \n",
    "        if state['query_is_unique']['status'] == True:\n",
    "            tool_calls = state['conversation'][-1].additional_kwargs['tool_calls'] # returns a list of dictionaries\n",
    "            query_output = state['tool_messages'][-1] # returns a list of tool messages\n",
    "\n",
    "            structured_outputs = []\n",
    "            for i in range(len(tool_calls)):\n",
    "                cypher_code = ast.literal_eval(tool_calls[i]['function']['arguments'])['query']\n",
    "                output = query_output[i].content\n",
    "                \n",
    "                if cypher_code:\n",
    "                    structured_outputs.append({'cypher_code': cypher_code, 'output': output})\n",
    "\n",
    "            return {'cypher_code_and_query_outputs': structured_outputs}\n",
    "        \n",
    "        else:\n",
    "            print(\"Query already exists, skipping structure_queried_data step\")\n",
    "            return\n",
    "    \n",
    "    ## Model extracts whatever it needs from the queried data\n",
    "    def extract_data(self, state: AgentState):\n",
    "        \n",
    "        if state['query_is_unique']['status'] == True:\n",
    "            # Prepare data to give it to the model\n",
    "            # NOTE: cypher_code_and_query_outputs has individual queries with their respective outputs. Here I am looping over the last (n) number of returned tool messages and grouping them together to give them to the model, because the model can call the tool multiple times and return multiple tool messages. So, I check the number of tool calls (n) and use it as the number of times to loop over the last cypher_code_and_query_outputs.\n",
    "            queried_data = []\n",
    "            last_tool_message = state['tool_messages'][-1]\n",
    "            for i in range(-1, -len(last_tool_message)-1, -1):\n",
    "                cypher_code = state['cypher_code_and_query_outputs'][i]['cypher_code']\n",
    "                output = state['cypher_code_and_query_outputs'][i]['output']\n",
    "                queried_data.append(f\"cypher code: {cypher_code}. output: {output}\")\n",
    "                \n",
    "            prompt = [SystemMessage(content=self.system)] + state['conversation'] + [HumanMessage(content= prompts.extractor_prompt.format(queried_data=queried_data))]\n",
    "        \n",
    "        else:\n",
    "            existing_output_index = state['query_is_unique']['index']\n",
    "            queried_data = state['cypher_code_and_query_outputs'][existing_output_index]['output']\n",
    "\n",
    "            prompt = [SystemMessage(content=self.system)] + state['conversation'] + [HumanMessage(content= prompts.extractor_prompt.format(queried_data=queried_data))]\n",
    "        \n",
    "        extracted_data = self.model.invoke(prompt)\n",
    "        return {\"extracted_data\": [extracted_data.content]}\n",
    "\n",
    "    ## Generate final output\n",
    "    def recommend_careers(self, state: AgentState):\n",
    "        prompt = [SystemMessage(content=self.system)] + state['conversation']\n",
    "        prompt = prompt + [HumanMessage(content= prompts.recommender_prompt.format(extracted_data=state['extracted_data'][-1]))]\n",
    "        \n",
    "        recommended_careers = self.model.invoke(prompt)\n",
    "        return {'conversation': [recommended_careers], 'tool_messages': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ChatGroq(temperature=0.8, groq_api_key=os.environ[\"GROQ_API_KEY\"], model_name=\"llama-3.1-70b-versatile\")\n",
    "model = ChatGroq(temperature=0.8, groq_api_key=os.environ[\"GROQ_API_KEY\"], model_name=\"llama3-70b-8192\")\n",
    "\n",
    "agent = Agent(model=model, tools=[query_graph], system=prompts.personality_scientist_prompt.format(schema=graph.structured_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = {'configurable': {'thread_id': \"1\"}}\n",
    "output = agent.graph.stream({\"conversation\": [HumanMessage(content=\"first option\")]}, thread, stream_mode='values')\n",
    "\n",
    "for message in output:\n",
    "    message['conversation'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = agent.graph.get_state(thread).values\n",
    "\n",
    "print(state['conversation'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels_from_query(cypher_code):\n",
    "  # Extract start index and end index of the labels example: (n:Occupation) => start is ( end is )\n",
    "  start = []\n",
    "  end = []\n",
    "  for i, character in enumerate(cypher_code):\n",
    "    if character == \"(\": start.append(i+1)\n",
    "    if character == \")\": end.append(i)\n",
    "\n",
    "  # Extract the labels using the start and end indicies. return labels as {'n': 'Occupation'...}\n",
    "  labels = {}\n",
    "  for i in range(len(start)):\n",
    "    label = cypher_code[start[i]: end[i]] # returns \"n:Occupation\"\n",
    "    label = label.split(\":\") # returns [\"n\", \"Occupation\"]\n",
    "\n",
    "    labels[label[0]] = label[1]\n",
    "\n",
    "  return labels\n",
    "\n",
    "\n",
    "def organize_queried_data(data, labels):\n",
    "  structured_queried_data = {'labels': list(labels.values()), 'relations': []}\n",
    "\n",
    "  for i in range(len(data)):\n",
    "    # extract keys (nodes' refrences as they were returned from the query's output. example: \"cypher code ... return n,m\")\n",
    "    row = data[i]\n",
    "    keys = list(row.keys()) # keys are the referenced labels. example: n:Occupation, so n is referencing Occupation\n",
    "    \n",
    "    # Extract node relations. example: Occupation: Teacher, Personality_Trait: Social\n",
    "    \n",
    "    relation = []\n",
    "    for i in range(len(keys)):\n",
    "      key = keys[i]\n",
    "      # label = labels[key]\n",
    "      properties = row[key]\n",
    "      \n",
    "      relation.append(properties)\n",
    "\n",
    "    structured_queried_data['relations'] += [relation]\n",
    "  \n",
    "  return structured_queried_data\n",
    "\n",
    "query_output = ast.literal_eval(state['cypher_code_and_query_outputs'][0]['output'])\n",
    "llm_query = state['cypher_code_and_query_outputs'][0]['cypher_code']\n",
    "\n",
    "labels = extract_labels_from_query(cypher_code=llm_query)\n",
    "outputs = organize_queried_data(data=query_output, labels=labels)\n",
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
